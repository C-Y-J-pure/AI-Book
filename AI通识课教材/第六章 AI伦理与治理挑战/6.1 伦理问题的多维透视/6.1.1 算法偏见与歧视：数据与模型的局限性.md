<p style="text-indent:2em">AI系统的“偏见基因”深植于数据土壤。当训练数据包含历史歧视，算法就会像海绵般吸收并放大偏见。美国某面部识别系统对深肤色人群的误判率高达34%，远超白种人群的0.8%误差。这种偏差源于早期数据库以白人照片为主，导致算法将深色皮肤与“风险指标”错误关联。更隐蔽的歧视出现在信贷领域：某银行AI系统给女性用户的信用评分普遍低于男性，只因历史贷款数据中男性还款比例更高。
</p>
